<!DOCTYPE html>
<html>
<header>
    <title>ONNX Runtime JavaScript examples: Quick Start - Web (using bundler)</title>
</header>

<body>
    <!-- consume a single file bundle -->
    <!--script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script-->
    <!--script src="../node_modules/onnxruntime-web/dist/ort.all.js"></script-->
    <script src="./web_cmp/dist/ort.all.js"></script>
    <script src="./ort-toolkit/models.js"></script>
    <script src="./ort-toolkit/util.js"></script>
    <!--script type="module" src="protobuf.js"></script-->
    <!--script type="module" src="onnx.js"></script-->
    <!--script src="../test/onnx.dev.js"></script-->
    <!--script type="module" src="onnxdecoder.js"></script-->
    <script type="module">
        // import * as onnxModule from "./onnx.js";
        import * as onnxdecoder from "./onnxdecoder.js";
        const onnxProto = ort.OnnxProto.onnx; //onnxModule.onnx;
        const modelName = 'albert-base-v2-all';//'mobilenetv2-12-opt';
        const deviceName = '-7779'
        async function getDataFromJsonFile(name) {
            // TODO: Fix constant node file not found.
            const response = await fetch(`./modeldata/${modelName}${deviceName}/` + name + ".json");
            const json = await response.json();
            if (json.type === 'float') {
                json.type = 'float32';
            }
            return json;
        }

        BigInt.prototype.toJSON = function () {
            return Number(this.toString());
        };

        function getParam(name) {
            name = name.replace(/[\[\]]/g, '\\$&');
            let regex = new RegExp('[?&]' + name + '(=([^&#]*)|&|#|$)', 'i');
            let results = regex.exec(window.location.href);
            if (!results)
                return null;
            if (!results[2])
                return '';
            return decodeURIComponent(results[2].replace(/\+/g, ' '));
        }

        async function generateGraphPlan(node) {
            const nodePlan = { name: node.name };
            nodePlan.inputs = [];
            nodePlan.outputs = [];
            const inputShapeDefinitions = [];

            try {
                for (const inputName of node.inputNames) {
                    nodePlan.inputs.push(await getDataFromJsonFile(inputName.replace(/\//g, '_').replace(/:/g, '_')));
                }
            } catch (e) {
                console.error(("Can not find input: " + node.name + ", " + JSON.stringify(node)));
                return null;
            }

            try {
                for (const outputName of node.outputNames) {
                    nodePlan.outputs.push(await getDataFromJsonFile(outputName.replace(/\//g, '_').replace(/:/g, '_')));
                }
            } catch (e) {
                console.error("Can not find output: " + node.name + ", " + JSON.stringify(node));
                return null;
            }

            for (const input of nodePlan['inputs'])
                inputShapeDefinitions.push((input['dims']));
            const attributs = [];
            node.attributes._attributes.forEach((value, key) => {
                console.log(key + ", " + value);
                attributs.push({ 'name': key, 'data': value[0], 'type': value[1] });
            }
            );
            let domain = { "domain": "com.microsoft", "version": 1 };
            if (node.opType === 'Add'
                || node.opType === 'Conv'
                || node.opType === 'Shape'
                || node.opType === 'Reshape'
                || node.opType === 'Gather'
                || node.opType === 'Unsqueeze'
                || node.opType === 'Concat'
                || node.opType === 'GlobalAveragePool'
                || node.opType === 'Slice'
                || node.opType === 'Cast'
                || node.opType === 'Softmax'
                || node.opType === 'MatMul'
                || node.opType === 'Sub'
                || node.opType === 'Mul'
                || node.opType === 'Add'
                || node.opType === 'Div'
                || node.opType === 'LayerNormalization'
                || node.opType === 'Transpose') {
                domain = { "domain": "", "version": 12 };
            }
            const graphPlan = {
                "name": node.opType,
                "operator": node.opType,
                "attributes": attributs,
                "inputShapeDefinitions": inputShapeDefinitions,
                "cases": [
                    nodePlan,
                ],
                "backend": getParam('ep') || 'wasm',
                // "opset": { "domain": "", "version": 12 }
                "opset": domain,
                //"opset": [{"domain":"","version":12},{"domain":"com.microsoft.nchwc","version":1},{"domain":"ai.onnx.ml","version":3},{"domain":"com.ms.internal.nhwc","version":19},{"domain":"ai.onnx.training","version":1},{"domain":"ai.onnx.preview.training","version":1},{"domain":"com.microsoft","version":1},{"domain":"com.microsoft.experimental","version":1},{"domain":"org.pytorch.aten","version":1}]
            };

            return graphPlan;
        }

        async function runGraphPlan(graphPlan) {
            //ort.env.debug = true
            //ort.env.logLevel = 'verbose';

            const model = onnxProto.ModelProto.create();
            model.irVersion = onnxProto.Version.IR_VERSION;
            // model.opsetImport.push(opsetImport);
            model.opsetImport = [{ "domain": "", "version": 12 },
            { "domain": "com.microsoft.nchwc", "version": 1 }, { "domain": "ai.onnx.ml", "version": 3 },
            { "domain": "com.ms.internal.nhwc", "version": 19 }, { "domain": "ai.onnx.training", "version": 1 },
            { "domain": "ai.onnx.preview.training", "version": 1 },
            { "domain": "com.microsoft", "version": 1 }, { "domain": "com.microsoft.experimental", "version": 1 }, { "domain": "org.pytorch.aten", "version": 1 }];
            model.graph = onnxProto.GraphProto.create();

            const case0 = graphPlan["cases"][0];
            // console.log('case0 : ' + JSON.stringify(case0));
            // TODO: outputs maybe array.
            const session = (await onnxdecoder.createOnnxModel(graphPlan, onnxProto));
            const result = await onnxdecoder.runProtoOpTestcase(session, case0);
            return result;
        }

        async function loadModel(arg, byteOffset, length) {
            // const model = new onnx.Model();
            const model = new ort.Model();
            if (typeof arg === 'string') {
                const isOrtFormat = arg.endsWith('.ort');
                if (typeof process !== 'undefined' && process.versions && process.versions.node) {
                    // node
                    const buf = await readFile(arg);
                    model.load(buf);
                } else {
                    // browser
                    const response = await fetch(arg);
                    const buf = await response.arrayBuffer();
                    model.load(new Uint8Array(buf));
                }
            } else if (!ArrayBuffer.isView(arg)) {
                // load model from ArrayBuffer
                const arr = new Uint8Array(arg, byteOffset || 0, length || arg.byteLength);
                //this.initialize(arr);
                model.load(arr);
            } else {
                model.load(arg);
            }
            return model;
        }
        // /albert/encoder/albert_layer_groups.0/albert_layers.0/attention/query/MatMul
        async function generateDumpData() {
            const session = await ort.InferenceSession.create(`./ort-models/${modelName}.onnx`);
            // prepare inputs. a tensor need its corresponding TypedArray as data
            const dataA = Float32Array.from([1, 2, 3]);
            const dataB = Float32Array.from([10, 20, 30]);
            const tensorA = new ort.Tensor('float32', dataA, [3]);
            const tensorB = new ort.Tensor('float32', dataB, [3]);
            // prepare feeds. use model input names as keys.
            const feeds = { a: tensorA, b: tensorB };

            // feed inputs and run
            const results = await session.run(feeds);

            // read from results
            const dataC = results.output2.data;
            console.log(dataC);
        }

        function convertArrayToBigInt64Array(array) {
            const bigint64array = new BigInt64Array(array.length);
            for (var i = 0; i < array.length; i++) {
                bigint64array[i] = BigInt(array[i]);
            }
            return bigint64array;
        }

        function compareIgnoreType(reference, result) {
            const isResultInt64 = result instanceof BigInt64Array;
            const referenceInt64 = isResultInt64 ? convertArrayToBigInt64Array(reference) : reference;
            if (isResultInt64) {
                return (JSON.stringify(referenceInt64.sort()) === JSON.stringify(result.sort()));
            }
            return compare(referenceInt64, Array.from(result));
        }

        async function compareSingleNode(node) {
            const graphPlan = await generateGraphPlan(node);
            if (graphPlan == null) {
                return;
            }
            const result1 = await runGraphPlan(graphPlan);
            let reference = graphPlan["cases"][0]['outputs'][0].data;
            const compareResult = compareIgnoreType(reference, result1.output_0.cpuData);
            if (compareResult)
                console.log("Wasm vs " + graphPlan["backend"] + ", compare result=" + compareResult + ","+ graphPlan["name"] + ", " + graphPlan["cases"][0]["name"]);
            else {
                console.log("CMP reference : " + JSON.stringify(reference));
                console.log("CMP result : " + JSON.stringify(Array.from(result1.output_0.cpuData)));
                console.error("Wasm vs " + graphPlan["backend"] + ", compare result=" +
                    compareResult + ", failed node: " + graphPlan["name"] + ", " + graphPlan["cases"][0]["name"]
                    + ", inputShapeDefinitions = " + JSON.stringify(graphPlan["inputShapeDefinitions"]));
            }
        }

        async function main() {
            // Step 1: generate dump data files.
            // await generateDumpData();
            // Step 2: get node list, then run and compare. 
            const model = await loadModel(`./ort-models/${modelName}.onnx`);
            const nodes = model.graph._nodes;
            const testNode = getParam("node");
            // "/albert/encoder/albert_layer_groups.0/albert_layers.0/attention/query/MatMul"
            if (testNode) {
                for (const node of nodes) {
                    if (testNode && node.name === testNode) {
                        await compareSingleNode(node);
                        break;
                    }
                }
            } else {
                for (const node of nodes) {
                    await compareSingleNode(node);
                }
            }
        }
        main();
    </script>
</body>

</html>
